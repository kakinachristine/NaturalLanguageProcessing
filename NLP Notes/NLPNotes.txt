Natural Language Preprocessing:

Content:
#Text Vectorization and pre-processing:
     VECTORIZATION(Frequency Based)
    -Bag of words(Simple frequency,Relative frequency,Text Frequency and Inverse document frequency)
    -Words may be unigrams/N-grams with N being 2,3,4.......
    ADVANCED VECTORIZATION
    -Text/word Embedding

    PRE-PROCESSING
    -Natural Language Preprocessing
    -Preprocessing in NLP
    -Tokenization: converts a single sentence/ text into single words
    -Lowercasing: convert all words to lowercase
    -Base form of the word: Convert words to single base form,finds unique word in words that share a common meaning(jump,jumped,jumping,jumps to jump) uses: stemming,lemmatization
    -stopword removal: removing common words that are for english like this, she , the e.t.c. This words are not important hence removal
    -Punctuation removal
    -Remove contraction e.g. from can't to cannot


#Movie Recommendation
    -
#Text embeddings
- this uses text relationships and semantics to classify words instead of frequency
- We  have CBOW nad Skip-gram
- Use of techniques like word2Vec, GloVe(global vectors for word representation),Bert(Bi-directional encoder
    representation from transformers) and FastText
-GloVe and FastText are pretrained models


#Text Classification
#Text Summarization