{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sentence Classification using LSTM and Pretrained Word2Vec",
   "id": "2c95ebda1ca62e26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We will train and test sentence classification using LSTM, and Pretrained Word2Vec.\n",
    "You can find visualization of our code below."
   ],
   "id": "4ec44e4a0aa084a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The most benefits from Pretrained Word Embedding is<br>even unseen words during traning can be predicted well, since pretrained word embedding already trained with larger data set than your train data.",
   "id": "ac518511073a734e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "for example, below example also can be predicted well, even \"this\", \"best\", \"show\" were not in the train data.<br> Since \"this\" is similar to \"it\", \"best\" is similar to \"good\" and \"show\" is similar to \"movie\" in pretrained word embedding vector.",
   "id": "85663b484b51d885"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will use LSTM, so we can generate sentence vector with sequence of word embedding.<br>LSTM is advanced RNN which is powerful on long sequence input.",
   "id": "68a72018ece520ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T11:51:30.419897Z",
     "start_time": "2025-07-25T11:51:30.407351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Import Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np"
   ],
   "id": "ffc0c9cd3b4bba0a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:23:37.414447Z",
     "start_time": "2025-07-25T10:23:33.987634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load Pretrained Word2Vec\n",
    "embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250/2\")"
   ],
   "id": "1cf517ad33428f6",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:23:37.542594Z",
     "start_time": "2025-07-25T10:23:37.449451Z"
    }
   },
   "cell_type": "code",
   "source": "embed([\"jump\"])",
   "id": "74ca0023357539fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 250), dtype=float32, numpy=\n",
       "array([[-0.00067931,  0.06408308,  0.0495666 ,  0.05925972, -0.01335577,\n",
       "         0.04213884, -0.0608239 ,  0.04894666, -0.07230948, -0.07469559,\n",
       "        -0.03064002,  0.05388073, -0.06971022,  0.00333765, -0.10572395,\n",
       "         0.00675618,  0.0339472 ,  0.01811906,  0.01162543, -0.00152522,\n",
       "         0.01761709,  0.05105859, -0.10164404, -0.02336321, -0.04341478,\n",
       "        -0.00348344,  0.03789383,  0.07577708,  0.02933779,  0.12435406,\n",
       "         0.11630959, -0.11019364,  0.01011824, -0.02797017,  0.05135059,\n",
       "        -0.04368721,  0.01803273,  0.11828327,  0.0704509 , -0.02574026,\n",
       "        -0.06336565, -0.12046516,  0.00759061,  0.05887634,  0.07620929,\n",
       "         0.08507296, -0.00164223,  0.09397715, -0.07488727,  0.00359939,\n",
       "         0.04454356, -0.03056428, -0.02355767,  0.10840571, -0.04652384,\n",
       "         0.02701746, -0.03696478,  0.01072006,  0.04460838,  0.01600937,\n",
       "         0.02497451, -0.03835671, -0.05878492,  0.00480731, -0.00065042,\n",
       "         0.02100394,  0.01093158, -0.01554795,  0.05285667, -0.01369335,\n",
       "        -0.0154726 ,  0.07718689,  0.04658276,  0.00126007,  0.11430036,\n",
       "        -0.02247827, -0.08943766, -0.03553804,  0.00685011, -0.00129195,\n",
       "        -0.16710867,  0.09009171,  0.11347975, -0.00931405,  0.10064586,\n",
       "         0.03616963, -0.02895578, -0.06264854, -0.00961302, -0.07664695,\n",
       "        -0.06234945, -0.01972457,  0.03304694, -0.03526219,  0.00383961,\n",
       "        -0.00048282, -0.01993902,  0.01367402,  0.05146534, -0.03588279,\n",
       "        -0.02219566,  0.02271184,  0.02802221,  0.03100744,  0.04394802,\n",
       "        -0.04472096,  0.06463436, -0.07267761, -0.00529684, -0.03510704,\n",
       "        -0.10918698,  0.03328404, -0.01193704, -0.02006921, -0.00402977,\n",
       "        -0.08753478, -0.11283202, -0.02935079,  0.01005594,  0.01075427,\n",
       "        -0.05758925, -0.21329339, -0.00651054,  0.04591168, -0.06500193,\n",
       "        -0.06294756, -0.03498026, -0.00729408,  0.05357447, -0.00917352,\n",
       "         0.00390237, -0.01937464, -0.02838963, -0.11373223,  0.01549466,\n",
       "         0.06665792,  0.02777765, -0.05509714, -0.11389618,  0.03819942,\n",
       "         0.02084623,  0.1604888 ,  0.06004076,  0.07355357, -0.04802546,\n",
       "         0.03871331, -0.02072838, -0.0729169 , -0.06340186, -0.01996394,\n",
       "        -0.10421651,  0.08858522, -0.05061435, -0.12913308,  0.11359692,\n",
       "         0.07791828,  0.08729292, -0.08191507, -0.00173057, -0.13352954,\n",
       "        -0.00844311, -0.01086278, -0.02129025, -0.11183329, -0.03593596,\n",
       "        -0.02066719,  0.05052205, -0.05136124, -0.03474869,  0.01272432,\n",
       "        -0.05832563,  0.02115768, -0.11588619,  0.0735872 ,  0.04288889,\n",
       "        -0.10046429, -0.01398653,  0.06472208, -0.06426561, -0.06772235,\n",
       "         0.07120418,  0.02718889,  0.0254877 ,  0.05480474, -0.00210784,\n",
       "         0.01220289,  0.05946621,  0.00476029, -0.06374492, -0.05245855,\n",
       "        -0.03594285,  0.06583928, -0.04612781,  0.07012784, -0.03828701,\n",
       "         0.13814738, -0.02027182, -0.05786486, -0.0215953 , -0.0826325 ,\n",
       "         0.03405377, -0.09490602, -0.11138967, -0.00904358,  0.02020896,\n",
       "        -0.01638606, -0.0124256 ,  0.11249047, -0.05330765, -0.04749723,\n",
       "        -0.00976528,  0.08043864,  0.06100198, -0.14907663,  0.08232154,\n",
       "         0.03932523,  0.05254515, -0.04020307, -0.03206441, -0.07846402,\n",
       "        -0.0804672 , -0.0883908 ,  0.08230038,  0.00025559, -0.10446916,\n",
       "        -0.0792898 ,  0.0921578 , -0.04808655, -0.11439429, -0.08440322,\n",
       "         0.10027943, -0.00854666,  0.15360786, -0.00273033, -0.03727837,\n",
       "         0.02058   ,  0.10409226, -0.01263275,  0.07520451, -0.04713498,\n",
       "         0.00462371,  0.0108196 ,  0.02127583, -0.02434942,  0.11104693,\n",
       "         0.00921015, -0.02100242, -0.06265114,  0.01594224,  0.06936075]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:23:37.702514Z",
     "start_time": "2025-07-25T10:23:37.681281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_max_length(df):\n",
    "    \"\"\"\n",
    "    get max token counts from train data,\n",
    "    so we use this number as fixed length input to RNN cell\n",
    "    \"\"\"\n",
    "    max_length = 0\n",
    "    for row in df['review']:\n",
    "        if len(row.split(\" \")) > max_length:\n",
    "            max_length = len(row.split(\" \"))\n",
    "    return max_length\n",
    "\n",
    "def get_word2vec_enc(reviews):\n",
    "    \"\"\"\n",
    "    get word2vec value for each word in sentence.\n",
    "    concatenate word in numpy array, so we can use it as RNN input\n",
    "    \"\"\"\n",
    "    encoded_reviews = []\n",
    "    for review in reviews:\n",
    "        tokens = review.split(\" \")\n",
    "        word2vec_embedding = embed(tokens)\n",
    "        encoded_reviews.append(word2vec_embedding)\n",
    "    return encoded_reviews\n",
    "\n",
    "def get_padded_encoded_reviews(encoded_reviews):\n",
    "    \"\"\"\n",
    "    for short sentences, we prepend zero padding so all input to RNN has same length\n",
    "    \"\"\"\n",
    "    padded_reviews_encoding = []\n",
    "    for enc_review in encoded_reviews:\n",
    "        zero_padding_cnt = maxLength - enc_review.shape[0]\n",
    "        pad = np.zeros((1, 250))\n",
    "        for i in range(zero_padding_cnt):\n",
    "            enc_review = np.concatenate((pad, enc_review), axis=0)\n",
    "        padded_reviews_encoding.append(enc_review)\n",
    "    return padded_reviews_encoding\n",
    "\n",
    "def sentiment_encode(sentiment):\n",
    "    \"\"\"\n",
    "    return one hot encoding for Y value\n",
    "    \"\"\"\n",
    "    if sentiment == 'positive':\n",
    "        return [1,0]\n",
    "    else:\n",
    "        return [0,1]\n",
    "\n",
    "def preprocess(df):\n",
    "    \"\"\"\n",
    "    encode text value to numeric value\n",
    "    \"\"\"\n",
    "    # encode words into word2vec\n",
    "    reviews = df['review'].tolist()\n",
    "\n",
    "    encoded_reviews = get_word2vec_enc(reviews)\n",
    "    padded_encoded_reviews = get_padded_encoded_reviews(encoded_reviews)\n",
    "    # encoded sentiment\n",
    "    sentiments = df['sentiment'].tolist()\n",
    "    encoded_sentiment = [sentiment_encode(sentiment) for sentiment in sentiments]\n",
    "    X = np.array(padded_encoded_reviews)\n",
    "    Y = np.array(encoded_sentiment)\n",
    "    return X, Y"
   ],
   "id": "62dcd93382786b79",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocess (encode text to number)",
   "id": "9655f5bc4a16f573"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:23:38.007683Z",
     "start_time": "2025-07-25T10:23:37.985139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "movieReviewsTrain = [\n",
    "         {'review': 'this is the best movie', 'sentiment': 'positive'},\n",
    "         {'review': 'i recommend you watch this movie', 'sentiment': 'positive'},\n",
    "         {'review': 'it was waste of money and time', 'sentiment': 'negative'},\n",
    "         {'review': 'the best acting but not movie', 'sentiment': 'negative'}\n",
    "    ]\n",
    "df = pd.DataFrame(movieReviewsTrain)\n",
    "\n",
    "df"
   ],
   "id": "3ecbe306b7b56454",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             review sentiment\n",
       "0            this is the best movie  positive\n",
       "1  i recommend you watch this movie  positive\n",
       "2    it was waste of money and time  negative\n",
       "3     the best acting but not movie  negative"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is the best movie</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i recommend you watch this movie</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it was waste of money and time</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the best acting but not movie</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:23:40.431893Z",
     "start_time": "2025-07-25T10:23:40.422662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# max_length is used for max sequence of input\n",
    "maxLength = get_max_length(df)\n",
    "\n",
    "maxLength"
   ],
   "id": "2cbef80d2531d43d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:23:40.829180Z",
     "start_time": "2025-07-25T10:23:40.794799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainX, trainY = preprocess(df)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "trainY"
   ],
   "id": "d0e714852345274f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7, 250)\n",
      "(4, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:23:41.067389Z",
     "start_time": "2025-07-25T10:23:41.051893Z"
    }
   },
   "cell_type": "code",
   "source": "trainY[1].size",
   "id": "24c3244915031760",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Build Model",
   "id": "b0bd0cb82d912cb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:23:41.305269Z",
     "start_time": "2025-07-25T10:23:41.263437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LSTM model\n",
    "model = Sequential()\n",
    "# model.add(RNN(16))\n",
    "model.add(LSTM(32))\n",
    "# model.add(LSTM(8))\n",
    "model.add(Dense(2, activation='softmax'))"
   ],
   "id": "7b1e0e19ae3646e9",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:23:41.477834Z",
     "start_time": "2025-07-25T10:23:41.437105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ],
   "id": "e611eb7b99e14d73",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train",
   "id": "4c3f423102681a13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:23:52.650022Z",
     "start_time": "2025-07-25T10:23:41.522005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Train...')\n",
    "model.fit(trainX, trainY,epochs=50)"
   ],
   "id": "768baec52f6c2fd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 6s/step - accuracy: 0.2500 - loss: 0.7054\n",
      "Epoch 2/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 128ms/step - accuracy: 0.2500 - loss: 0.6970\n",
      "Epoch 3/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 119ms/step - accuracy: 0.5000 - loss: 0.6888\n",
      "Epoch 4/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 115ms/step - accuracy: 0.7500 - loss: 0.6808\n",
      "Epoch 5/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 108ms/step - accuracy: 0.7500 - loss: 0.6729\n",
      "Epoch 6/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 118ms/step - accuracy: 0.7500 - loss: 0.6648\n",
      "Epoch 7/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 106ms/step - accuracy: 0.7500 - loss: 0.6566\n",
      "Epoch 8/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 117ms/step - accuracy: 0.7500 - loss: 0.6482\n",
      "Epoch 9/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 104ms/step - accuracy: 0.7500 - loss: 0.6395\n",
      "Epoch 10/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 112ms/step - accuracy: 0.7500 - loss: 0.6304\n",
      "Epoch 11/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 113ms/step - accuracy: 0.7500 - loss: 0.6209\n",
      "Epoch 12/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 106ms/step - accuracy: 0.7500 - loss: 0.6109\n",
      "Epoch 13/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 119ms/step - accuracy: 0.7500 - loss: 0.6004\n",
      "Epoch 14/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 118ms/step - accuracy: 0.7500 - loss: 0.5893\n",
      "Epoch 15/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 124ms/step - accuracy: 0.7500 - loss: 0.5776\n",
      "Epoch 16/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 97ms/step - accuracy: 1.0000 - loss: 0.5653\n",
      "Epoch 17/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 103ms/step - accuracy: 1.0000 - loss: 0.5523\n",
      "Epoch 18/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 122ms/step - accuracy: 1.0000 - loss: 0.5386\n",
      "Epoch 19/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 96ms/step - accuracy: 1.0000 - loss: 0.5242\n",
      "Epoch 20/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 97ms/step - accuracy: 1.0000 - loss: 0.5091\n",
      "Epoch 21/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 94ms/step - accuracy: 1.0000 - loss: 0.4933\n",
      "Epoch 22/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 109ms/step - accuracy: 1.0000 - loss: 0.4768\n",
      "Epoch 23/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 116ms/step - accuracy: 1.0000 - loss: 0.4596\n",
      "Epoch 24/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 103ms/step - accuracy: 1.0000 - loss: 0.4418\n",
      "Epoch 25/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 96ms/step - accuracy: 1.0000 - loss: 0.4235\n",
      "Epoch 26/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 96ms/step - accuracy: 1.0000 - loss: 0.4047\n",
      "Epoch 27/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 105ms/step - accuracy: 1.0000 - loss: 0.3856\n",
      "Epoch 28/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 106ms/step - accuracy: 1.0000 - loss: 0.3660\n",
      "Epoch 29/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 95ms/step - accuracy: 1.0000 - loss: 0.3463\n",
      "Epoch 30/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 95ms/step - accuracy: 1.0000 - loss: 0.3263\n",
      "Epoch 31/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 106ms/step - accuracy: 1.0000 - loss: 0.3062\n",
      "Epoch 32/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 83ms/step - accuracy: 1.0000 - loss: 0.2861\n",
      "Epoch 33/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 93ms/step - accuracy: 1.0000 - loss: 0.2659\n",
      "Epoch 34/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 90ms/step - accuracy: 1.0000 - loss: 0.2457\n",
      "Epoch 35/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 97ms/step - accuracy: 1.0000 - loss: 0.2258\n",
      "Epoch 36/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 74ms/step - accuracy: 1.0000 - loss: 0.2061\n",
      "Epoch 37/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 89ms/step - accuracy: 1.0000 - loss: 0.1869\n",
      "Epoch 38/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 95ms/step - accuracy: 1.0000 - loss: 0.1683\n",
      "Epoch 39/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 101ms/step - accuracy: 1.0000 - loss: 0.1505\n",
      "Epoch 40/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 77ms/step - accuracy: 1.0000 - loss: 0.1337\n",
      "Epoch 41/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 112ms/step - accuracy: 1.0000 - loss: 0.1179\n",
      "Epoch 42/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 102ms/step - accuracy: 1.0000 - loss: 0.1033\n",
      "Epoch 43/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 93ms/step - accuracy: 1.0000 - loss: 0.0900\n",
      "Epoch 44/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 94ms/step - accuracy: 1.0000 - loss: 0.0781\n",
      "Epoch 45/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 104ms/step - accuracy: 1.0000 - loss: 0.0675\n",
      "Epoch 46/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 96ms/step - accuracy: 1.0000 - loss: 0.0584\n",
      "Epoch 47/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 99ms/step - accuracy: 1.0000 - loss: 0.0505\n",
      "Epoch 48/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 85ms/step - accuracy: 1.0000 - loss: 0.0437\n",
      "Epoch 49/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 78ms/step - accuracy: 1.0000 - loss: 0.0380\n",
      "Epoch 50/50\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 82ms/step - accuracy: 1.0000 - loss: 0.0332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24538dad390>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:23:56.190207Z",
     "start_time": "2025-07-25T10:23:56.069413Z"
    }
   },
   "cell_type": "code",
   "source": "model.summary()\n",
   "id": "da71c6a414e03070",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │        \u001B[38;5;34m36,224\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m)              │            \u001B[38;5;34m66\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m108,872\u001B[0m (425.29 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">108,872</span> (425.29 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m36,290\u001B[0m (141.76 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,290</span> (141.76 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m72,582\u001B[0m (283.53 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,582</span> (283.53 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test\n",
    "your model can predict correctly even for unseen words from training.\n",
    "This is the most benefit of using pretrained word embedding.\n",
    "Why? pretrained embedding will encode [better], [nice] to similar vector of [best]\n",
    "even if these words were not in train.\n",
    "therefore, the input vector to RNN is similar, so correct answers for even these unseen words."
   ],
   "id": "fc8c972604569db2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:23:57.379677Z",
     "start_time": "2025-07-25T10:23:56.260648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "movie_reviews_train = [\n",
    "         {'review': 'this is the best movie', 'sentiment': 'positive'},\n",
    "         {'review': 'i recommend you watch this movie', 'sentiment': 'positive'},\n",
    "         {'review': 'it was waste of money and time', 'sentiment': 'negative'},\n",
    "         {'review': 'the best acting but no movie', 'sentiment': 'negative'}\n",
    "    ]\n",
    "\"\"\"\n",
    "movieReviewsTest = [\n",
    "         {'review': 'it is better movie', 'sentiment': 'positive'},\n",
    "         {'review': 'i suggest you see this movie', 'sentiment': 'positive'},\n",
    "         {'review': 'it was just throwing 20 dollars away', 'sentiment': 'negative'},\n",
    "         {'review': 'worse than any show', 'sentiment': 'negative'},\n",
    "         {'review': 'nice movie, so love it', 'sentiment': 'positive'},\n",
    "         {'review': 'terrible', 'sentiment': 'negative'}\n",
    "    ]\n",
    "testDf = pd.DataFrame(movieReviewsTest)\n",
    "\n",
    "testX, testY = preprocess(testDf)\n",
    "\n",
    "score, acc = model.evaluate(testX, testY, verbose=2)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ],
   "id": "adf42c6e359959ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 1s - 1s/step - accuracy: 0.6667 - loss: 0.5422\n",
      "Test score: 0.5421934127807617\n",
      "Test accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T10:23:57.432671Z",
     "start_time": "2025-07-25T10:23:57.424130Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "585444b74567cd71",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
